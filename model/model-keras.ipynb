{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model built with raw TensorFlow\n",
    "\n",
    "This model is an attempt to drop HuggingFace transformers library and use pure TensorFlow code.\n",
    "\n",
    "The goal is to get a single source of truth and to use directly Google's models.\n",
    "\n",
    "Adapted from: <https://www.tensorflow.org/text/tutorials/classify_text_with_bert>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import tensorflowjs as tfjs\n",
    "#from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "# Data\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Custom\n",
    "from helper_functions import load_sst_dataset, plot_model_history, save_ts_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TensorFlow to log only the errors\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Force the use of the CPU instead of the GPU if running out of GPU memory\n",
    "device = '/CPU:0' # input '/CPU:0' to use the CPU or '/GPU:0' for the GPU\n",
    "\n",
    "# Model to be used\n",
    "bert_model_name         = 'small_bert/bert_en_uncased_L-2_H-128_A-2'\n",
    "tfhub_handle_encoder    = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "\n",
    "\n",
    "# Tokenizing parameters\n",
    "max_length = 60    # Max length of an input\n",
    "\n",
    "# Training parameters\n",
    "epochs = 1  # 1 is enough for code testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset sst (C:\\Users\\thiba\\.cache\\huggingface\\datasets\\sst\\default\\1.0.0\\b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1000.23it/s]\n"
     ]
    }
   ],
   "source": [
    "text_train, Y1, Y2, text_test, Y1_test, Y2_test = load_sst_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For preprocessing\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "\n",
    "# Bert itself\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "  # Input\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "\n",
    "  # Preprocessing \n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "\n",
    "  # Encoder\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "\n",
    "  # Encoder's output\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "\n",
    "  # Classifier\n",
    "  regression = tf.keras.layers.Dense(1, name='regression', activation=None)(net)\n",
    "  classifier = tf.keras.layers.Dense(1, name='classifier', activation='sigmoid')(net)\n",
    "\n",
    "  # Final output\n",
    "  outputs = {'regression': regression, 'classifier': classifier}\n",
    "\n",
    "  # Return the model\n",
    "  return tf.keras.Model(text_input, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function used\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "# Metric for results evaluation\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=5e-05,\n",
    "        epsilon=1e-08,\n",
    "        decay=0.01,\n",
    "        clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training input\n",
    "x = {'text': tf.convert_to_tensor(text_train)}\n",
    "\n",
    "# Training output\n",
    "y = {'classifier': Y2, 'regression':Y1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 125s 1s/step - loss: 4.4135 - classifier_loss: 0.7161 - regression_loss: 3.6974 - classifier_binary_accuracy: 0.5279 - regression_binary_accuracy: 0.0022 - val_loss: 1.5076 - val_classifier_loss: 0.7811 - val_regression_loss: 0.7264 - val_classifier_binary_accuracy: 0.2844 - val_regression_binary_accuracy: 0.0023\n"
     ]
    }
   ],
   "source": [
    "# doc: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
    "history = model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    validation_split=0.2,\n",
    "    batch_size=64,\n",
    "    epochs=epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 26s 254ms/step - loss: 1.4230 - classifier_loss: 0.7068 - regression_loss: 0.7161 - classifier_binary_accuracy: 0.4953 - regression_binary_accuracy: 0.0033\n"
     ]
    }
   ],
   "source": [
    "# Test input\n",
    "x_test = {'text': tf.convert_to_tensor(text_test)}\n",
    "\n",
    "# Test output\n",
    "y_test = {'classifier': Y2_test, 'regression':Y1_test}\n",
    "\n",
    "model_eval = model.evaluate(\n",
    "    x=x_test,\n",
    "    y=y_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model with model.save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: <https://www.tensorflow.org/api_docs/python/tf/keras/Model#save>\n",
    "\n",
    "```save_format```\n",
    "\n",
    "- tf: Tensorflow SavedModel\n",
    "- h5: HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# Save to Tensorflow SavedModel\n",
    "model.save(\"./formats/tf_savedmodel\",save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to HDF5\n",
    "model.save('./formats/tf_hdf5/model.h5',save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model with tensorflowjs_converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: <https://github.com/tensorflow/tfjs/tree/master/tfjs-converter>\n",
    "\n",
    "\n",
    "```--input_format```\n",
    "\n",
    "- tf_saved_model: SavedModel\n",
    "- tfjs_layers_model: TensorFlow.js JSON format\n",
    "- keras: Keras HDF5\n",
    "\n",
    "```--output_format```\n",
    "\n",
    "- tfjs_layers_model\n",
    "- tfjs_graph_model\n",
    "- keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras HDF5 --> tfjs_layers_model\n",
    "!tensorflowjs_converter --input_format keras --output_format tfjs_layers_model ./formats/tf_hdf5/model.h5 ./formats/tfjs_layers_model_from_keras_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 813, in pip_main\n",
      "    main([' '.join(sys.argv[1:])])\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 817, in main\n",
      "    convert(argv[0].split(' '))\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 803, in convert\n",
      "    _dispatch_converter(input_format, output_format, args, quantization_dtype_map,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 504, in _dispatch_converter\n",
      "    dispatch_keras_h5_to_tfjs_graph_model_conversion(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 140, in dispatch_keras_h5_to_tfjs_graph_model_conversion\n",
      "    model = tf.keras.models.load_model(h5_path, compile=False)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\saving\\save.py\", line 200, in load_model\n",
      "    return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\saving\\hdf5_format.py\", line 180, in load_model_from_hdf5\n",
      "    model = model_config_lib.model_from_config(model_config,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\saving\\model_config.py\", line 52, in model_from_config\n",
      "    return deserialize(config, custom_objects=custom_objects)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\layers\\serialization.py\", line 208, in deserialize\n",
      "    return generic_utils.deserialize_keras_object(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 674, in deserialize_keras_object\n",
      "    deserialized_obj = cls.from_config(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\engine\\functional.py\", line 662, in from_config\n",
      "    input_tensors, output_tensors, created_layers = reconstruct_from_config(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\engine\\functional.py\", line 1273, in reconstruct_from_config\n",
      "    process_layer(layer_data)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\engine\\functional.py\", line 1255, in process_layer\n",
      "    layer = deserialize_layer(layer_data, custom_objects=custom_objects)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\layers\\serialization.py\", line 208, in deserialize\n",
      "    return generic_utils.deserialize_keras_object(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 659, in deserialize_keras_object\n",
      "    (cls, cls_config) = class_and_config_for_serialized_keras_object(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 556, in class_and_config_for_serialized_keras_object\n",
      "    raise ValueError(\n",
      "ValueError: Unknown layer: KerasLayer. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "# Keras HDF5 --> tfjs_graph_model\n",
    "!tensorflowjs_converter --input_format keras --output_format tfjs_graph_model ./formats/tf_hdf5/model.h5 ./formats/tfjs_graph_model_from_keras_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 813, in pip_main\n",
      "    main([' '.join(sys.argv[1:])])\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 817, in main\n",
      "    convert(argv[0].split(' '))\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 803, in convert\n",
      "    _dispatch_converter(input_format, output_format, args, quantization_dtype_map,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 583, in _dispatch_converter\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported input_format - output_format pair: tf_saved_model - tfjs_layers_model\n"
     ]
    }
   ],
   "source": [
    "# tf_saved_model --> tfjs_layers_model\n",
    "!tensorflowjs_converter --input_format tf_saved_model --output_format=tfjs_layers_model ./formats/tf_savedmodel ./formats/tfjs_layers_model_from_tf_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 21:13:22.786947: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-17 21:13:23.483860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1789 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3962, in _get_op_def\n",
      "    return self._op_def_cache[type]\n",
      "KeyError: 'CaseFoldUTF8'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 902, in load_internal\n",
      "    loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 137, in __init__\n",
      "    function_deserialization.load_function_def_library(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py\", line 388, in load_function_def_library\n",
      "    func_graph = function_def_lib.function_def_to_graph(copy)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py\", line 63, in function_def_to_graph\n",
      "    graph_def, nested_to_flat_tensor_name = function_def_to_graph_def(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py\", line 228, in function_def_to_graph_def\n",
      "    op_def = default_graph._get_op_def(node_def.op)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3966, in _get_op_def\n",
      "    pywrap_tf_session.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type),\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'CaseFoldUTF8' in binary running on IDEAPAD. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 813, in pip_main\n",
      "    main([' '.join(sys.argv[1:])])\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 817, in main\n",
      "    convert(argv[0].split(' '))\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 803, in convert\n",
      "    _dispatch_converter(input_format, output_format, args, quantization_dtype_map,\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 523, in _dispatch_converter\n",
      "    tf_saved_model_conversion_v2.convert_tf_saved_model(\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\", line 599, in convert_tf_saved_model\n",
      "    model = _load_model(saved_model_dir, saved_model_tags)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\", line 536, in _load_model\n",
      "    model = load(saved_model_dir, saved_model_tags)\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 864, in load\n",
      "    result = load_internal(export_dir, tags, options)[\"root\"]\n",
      "  File \"C:\\Users\\thiba\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 905, in load_internal\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: Op type not registered 'CaseFoldUTF8' in binary running on IDEAPAD. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      " If trying to load on a different device from the computational device, consider using setting the `experimental_io_device` option on tf.saved_model.LoadOptions to the io_device such as '/job:localhost'.\n"
     ]
    }
   ],
   "source": [
    "# tf_saved_model --> tfjs_graph_model\n",
    "!tensorflowjs_converter --input_format tf_saved_model --output_format=tfjs_graph_model ./formats/tf_savedmodel ./formats/tfjs_graph_model_from_tf_saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export directly the model with tfjs convertors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suggested in: <https://www.tensorflow.org/js/tutorials/conversion/import_keras>\n",
    "\n",
    "Where is the API documentation of tfjs.converters ?\n",
    "\n",
    "From our test, it saves the model to the tfjs_layers_model format by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save directly\n",
    "tfjs.converters.save_keras_model(model, './formats/tfjs-direct')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2746d9c64e29f9893c214eba62327777aca31528b4dbe079e4edbeaaba40eb2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('bert': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
